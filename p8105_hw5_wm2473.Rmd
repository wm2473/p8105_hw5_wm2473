---
title: "p8105_hw5_wm2473"
output: github_document
date: "2022-11-14"
---

```{r}
library(tidyverse)
library(readxl)
library(rvest)
library(ggplot2)
set.seed(1)

```

## Problem 1
The code chunk below imports the data in individual spreadsheets contained in `./data/zip_data/`. To do this, I create a dataframe that includes the list of all files in that directory and the complete path to each file. As a next step, I `map` over paths and import data using the `read_csv` function. Finally, I `unnest` the result of `map`.

```{r}
full_df = 
  tibble(
    files = list.files("data/zip_data/"),
    path = str_c("data/zip_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```

The result of the previous code chunk isn't tidy -- data are wide rather than long, and some important variables are included as parts of others. The code chunk below tides the data using string manipulations on the file, converting from wide to long, and selecting relevant variables. 

```{r}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

Finally, the code chunk below creates a plot showing individual data, faceted by group. 

```{r}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

This plot suggests high within-subject correlation -- subjects who start above average end up above average, and those that start below average end up below average. Subjects in the control group generally don't change over time, but those in the experiment group increase their outcome in a roughly linear way. 
Problem 2
```{r}
#Describe the raw data: For the homicides raw dataset, it contains 52179 observations and 12 variables (columns), which are respectively uid, reported_date, victim_last, victim_first, victim_race, victim_age, victim_sex, city, state, latitude, longtitude, disposition. There are some NA missing value in latitude and longtitude column. Also, in the columns "race", "age" and "sex" contains data unknown which can indeciate that the person information is still misiing. There is a place Tulsa, one of the data is not in OK but in AL state. 

hd = read_csv("homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  na.omit() %>% 
   mutate(city_state = str_c(city,",", state), 
         homicides = case_when(disposition == "Closed without arrest" ~ "unsolved homicides", disposition == "Open/No arrest" ~ "unsolved homicides", disposition == "Closed by arrest" ~ "solved homicides")) %>%
  filter(city_state != "Tulsa,AL") %>% 
  relocate(city_state)


hd %>% 
  group_by(city_state, homicides) %>% 
  count() %>% 
  knitr::kable()
```

estimate the unsolved proportion of homicides in Baltimore, MD
```{r}
Baltimore = hd %>%
  filter(city_state == "Baltimore,MD") %>%  
  summarise(
    unsolved = sum(homicides == "unsolved homicides"),
    n = n()
  )

Baltimore_test = 
  prop.test(
    x = Baltimore %>% pull(unsolved),
    n = Baltimore %>% pull(n))

Baltimore_test %>% 
  broom::tidy() 
```

Prop.test for each of the city
```{r}
city_proptest = function(city_df){
  city_summarize = city_df %>%
  summarise(
    unsolved = sum(homicides == "unsolved homicides"),
    n = n())
  
  city_test = 
  prop.test(
    x = city_summarize %>% pull(unsolved),
    n = city_summarize %>% pull(n))
  
  return(city_test)
}
```

Create a tidy dataframe with estimated proportions and CIs for each city
```{r}
nested_df = hd %>%
  nest(alldata = uid:homicides) %>% 
  mutate(
    test_results = map(alldata, city_proptest),
    cleanresults = map(test_results, broom::tidy)
  ) %>% 
  select(city_state, cleanresults) %>% 
  unnest(cleanresults) %>% 
  select(city_state, estimate, starts_with("conf"))
```
Creat the plot
```{r}
nested_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point()+geom_errorbar(aes(ymin = conf.low, ymax = conf.high))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1), 
        plot.title = element_text(hjust = 0.5)) +
  labs(title = "Estimate vale among different city with errorbar",
       x = "City(State)",
       y = "Estimate") 
```

Problem 3
t_test function
```{r}
norm_and_t_test = function(mu) {
  sim_data = tibble(
    x = rnorm(n = 30, mean = mu, sd = 5),
  )  
    t.test(sim_data, mu =0, conf.level = 0.95, alternative = "two.sided") %>%
    broom::tidy() %>% 
    select(estimate, p.value)
}
```
testing mean=0
```{r}
sim_reuslt_df_0=
  expand_grid(
    true_mean=0,
    iter=1:5000)%>%
  mutate(results=map(true_mean,norm_and_t_test))%>%
  unnest(results)
head(sim_reuslt_df_0)
```

using the function for mean=1,2,3,4,5,6
```{r}
sim_results_df = 
  expand_grid(
    mu = c(1, 2, 3, 4, 5, 6),
    iter = 1:5000) %>% 
  mutate(results = map(mu, norm_and_t_test)) %>% 
  unnest(results)
head(sim_results_df)
```

First plot(mu vs. proportion of reject)
```{r}
mu_prop = sim_results_df %>% 
  mutate(decision = case_when(p.value < 0.05 ~ "reject", p.value >= 0.05 ~ "fail_to_reject")) %>% 
  group_by(mu) %>% 
  summarize(n_obs = n(), prop_reject = sum(decision == "reject") / n_obs)%>%
  ggplot(aes(x = mu, y = prop_reject)) + geom_point() +geom_smooth(alpha = .5)+labs(title = "Power vs. True mean",x = "True mean", y = "Power")+scale_x_continuous(breaks = 1:6)

mu_prop

# Describe the association between effect size and power: The power in the x-axis is we calculating the proportion of times the null was rejected (p_value < 0.05). The effect size in the y-axis is our true mean from 1 to 6. From the graph, we can see that the power will increase when the effect size increase. There is a positively proportional relationship between the effect size and power. 
```

Second graph (true value mu vs. average estimate of mu)
```{r}
true_estimate = sim_results_df %>% 
  mutate(decision = case_when(p.value < 0.05 ~ "reject", p.value >= 0.05 ~ "fail_to_reject")) %>% 
  group_by(mu) %>% 
  summarize(average_estimate = mean(estimate)) %>% 
  ggplot(aes(x = mu, y = average_estimate)) +
  geom_point()+ geom_line(alpha = .5)+ labs(title = "True value mu vs. Average estimate of mean",
    x = "True mean",
    y = "Average estimated mean"
  )+scale_x_continuous(breaks = 1:6)
true_estimate  
```

Third graph (true mean vs. average estimate of mu only only in samples for which the null was rejected)
```{r}
sd = sim_results_df %>% 
  mutate(decision = case_when(p.value < 0.05 ~ "reject", p.value >= 0.05 ~ "fail_to_reject")) %>% 
  filter(decision == "reject") %>%
  group_by(mu) %>% 
  summarize(average_estimate = mean(estimate), null_reject = sum(p.value)) %>% 
  ggplot(aes(x = mu, y = average_estimate))+ geom_point()+
  geom_smooth()+ labs(title="True mean vs. Average estimate of mean(null was rejected)",
         x="True mean",
         y="Estimated mean")+scale_x_continuous(breaks = 1:6)
sd
```

```{r}
# Is the sample average of the observed mu across tests for which the null is rejected approximately equal to the true value of mu? Why or why not?
# For comparing two graphs, we can see that the true mean 4, 5, 6 has a similar output for both estimate and observed mean. We found that the true mean 1, 2 and 3 is a little bit overestimated than the observed one. So the sample average of the observed mu across tests for which the null is rejected is not a good approximation of the true mean. We can also look at the p_value in the test results which is significant (significant different from the estimated mean and the true mean), we can reject the null from this result. 
```

